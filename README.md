# PrÃ©diction de Sentiments des Tweets avec MLOps

## ğŸ“Œ Description du Projet
Ce projet vise Ã  prÃ©dire le sentiment associÃ© Ã  un tweet (positif ou nÃ©gatif) en utilisant diffÃ©rentes approches d'apprentissage automatique et de deep learning. L'API dÃ©ployÃ©e sur Heroku permet d'envoyer un tweet en entrÃ©e et de recevoir une prÃ©diction de sentiment en sortie.

## ğŸš€ FonctionnalitÃ©s
- **Trois approches de modÃ©lisation** :
  - ModÃ¨le classique (rÃ©gression logistique)
  - ModÃ¨le avancÃ© (LSTM avec embeddings)
  - ModÃ¨le BERT
- **Gestion des expÃ©rimentations avec MLFlow** :
  - Suivi des performances des modÃ¨les
  - Stockage et versioning des modÃ¨les
- **DÃ©ploiement de l'API sur Heroku**
- **Interface de test avec Streamlit et Postman**
- **Suivi de performance avec Azure Application Insights**
  - Logs des prÃ©dictions et erreurs
  - Alerte e-mail en cas d'anomalie

## ğŸ“‚ Arborescence du Repository
```
â”œâ”€â”€ .github/workflows/    # CI/CD (Tests et dÃ©ploiement automatique)
â”œâ”€â”€ tests/                # Tests unitaires
â”œâ”€â”€ mlruns/               # Logs des expÃ©riences MLFlow
â”œâ”€â”€ .heroku-repo/         # DÃ©ploiement Heroku
â”œâ”€â”€ app.py                # API FastAPI
â”œâ”€â”€ streamlit_app.py      # Interface utilisateur
â”œâ”€â”€ requirements.txt      # DÃ©pendances Python
â”œâ”€â”€ Procfile              # Configuration Heroku
â”œâ”€â”€ README.md             # Documentation
â”œâ”€â”€ runtime.txt           # Version Python pour Heroku
â”œâ”€â”€ tokenizer.pkl         # Tokenizer sauvegardÃ©
â”œâ”€â”€ lstm_model.keras      # ModÃ¨le entraÃ®nÃ© (LSTM)
â”œâ”€â”€ mlflow.db             # Base de donnÃ©es MLFlow
```

## ğŸ›  Installation et ExÃ©cution
### 1ï¸âƒ£ Cloner le Repository
```bash
git clone https://github.com/ton-repo/mlops-tweet-analysis.git
cd mlops-tweet-analysis
```

### 2ï¸âƒ£ Installer les DÃ©pendances
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Lancer l'API Localement
```bash
uvicorn app:app --host 0.0.0.0 --port 8000
```
L'API sera accessible sur : `http://localhost:8000`

### 4ï¸âƒ£ Tester l'API avec Postman
Envoyer une requÃªte POST avec un tweet :
```json
{
  "tweet": "Le vol a Ã©tÃ© annulÃ©, je suis trÃ¨s mÃ©content !"
}
```
RÃ©ponse attendue :
```json
{
  "sentiment": "nÃ©gatif"
}
```

### 5ï¸âƒ£ Lancer l'Interface Streamlit
```bash
streamlit run streamlit_app.py
```

## ğŸ”— Liens Utiles
- **API en production** : [Lien Heroku](https://news-app-azure-47b93008885f.herokuapp.com/)
- **MLFlow Tracking** : [Lien MLFlow](http://localhost:5002)
- **DÃ©pÃ´t GitHub** : [Lien vers GitHub](https://github.com/ilb93/test_api.git)
- **Azure Application Insights** : Configuration et logs visibles dans Azure Portal

## âœ¨ Auteurs
- **Mourad** - DÃ©veloppement et mise en production
- **MIC - Marketing Intelligence Consulting** - Commanditaire du projet

---
ğŸš€ Ce projet illustre une dÃ©marche complÃ¨te d'IA appliquÃ©e avec MLOps pour la gestion et le dÃ©ploiement efficace de modÃ¨les de Machine Learning.
