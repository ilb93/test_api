# ğŸ“Š PrÃ©diction de Sentiments des Tweets avec MLOps

## ğŸ“Œ Description du Projet  
Ce projet vise Ã  **prÃ©dire le sentiment d'un tweet** (positif ou nÃ©gatif) en utilisant diffÃ©rentes approches d'apprentissage automatique et de deep learning.  

L'API dÃ©ployÃ©e sur **Heroku** permet d'envoyer un tweet en entrÃ©e et de recevoir une prÃ©diction de sentiment en sortie.  
Le suivi des performances et le monitoring sont effectuÃ©s grÃ¢ce Ã  **MLFlow** et **Azure Application Insights**.....

---

## ğŸ§  Approches de ModÃ©lisation  

Trois approches ont Ã©tÃ© testÃ©es :  
1ï¸âƒ£ **ModÃ¨le Classique** : RÃ©gression Logistique sur des TF-IDF.  
2ï¸âƒ£ **ModÃ¨le LSTM** : RÃ©seau de neurones rÃ©current avec embeddings GloVe.  
3ï¸âƒ£ **ModÃ¨le BERT** : Fine-tuning de `DistilBERT` pour classification binaire.

âœ”ï¸ **Choix final** : **LSTM**, car il offre un bon compromis entre **performance** et **spÃ©cificitÃ©**.  
   - **SpÃ©cificitÃ© Ã©levÃ©e** sur les tweets nÃ©gatifs, rÃ©duisant les faux positifs.  
   - Temps dâ€™infÃ©rence **plus rapide** que BERT.

---

## ğŸ”§ FonctionnalitÃ©s  
âœ… **API REST** sur Heroku (prÃ©vision en temps rÃ©el).  
âœ… **Interface de test** Streamlit pour visualiser les prÃ©dictions.  
âœ… **Gestion des expÃ©riences** avec **MLFlow** (tracking des modÃ¨les).  
âœ… **Monitoring en production** via **Azure Application Insights**.  
âœ… **Alertes e-mails** en cas dâ€™anomalie (mauvaises prÃ©dictions rÃ©pÃ©tÃ©es).  
âœ… **Tests unitaires** pour garantir le bon fonctionnement de lâ€™API.

---

## ğŸ“‚ Arborescence du Repository  
ğŸ“¦ projet_sentiment_analysis â”œâ”€â”€ .github/workflows/ # CI/CD (Tests et dÃ©ploiement automatique) â”œâ”€â”€ tests/ # Tests unitaires â”œâ”€â”€ mlruns/ # Logs des expÃ©riences MLFlow â”œâ”€â”€ .heroku-repo/ # DÃ©ploiement Heroku â”œâ”€â”€ notebooks/ # Notebooks d'entraÃ®nement des modÃ¨les â”œâ”€â”€ app.py # API FastAPI â”œâ”€â”€ streamlit_app.py # Interface utilisateur â”œâ”€â”€ requirements.txt # DÃ©pendances Python â”œâ”€â”€ Procfile # Configuration Heroku â”œâ”€â”€ README.md # Documentation â”œâ”€â”€ runtime.txt # Version Python pour Heroku â”œâ”€â”€ tokenizer.pkl # Tokenizer sauvegardÃ© â”œâ”€â”€ lstm_model.keras # ModÃ¨le entraÃ®nÃ© (LSTM) â”œâ”€â”€ mlflow.db # Base de donnÃ©es MLFlow

yaml
Copier
Modifier

---

## ğŸ›  Installation et ExÃ©cution  

### 1ï¸âƒ£ **Cloner le Repository**  
```bash
git clone https://github.com/ilb93/test_api.git
cd test_api
2ï¸âƒ£ Installer les DÃ©pendances
bash
Copier
Modifier
pip install -r requirements.txt
3ï¸âƒ£ Lancer l'API Localement
bash
Copier
Modifier
uvicorn app:app --host 0.0.0.0 --port 8000
L'API sera accessible sur : http://localhost:8000

4ï¸âƒ£ Tester l'API avec Postman
ğŸ“© RequÃªte POST /predict

json
Copier
Modifier
{
  "tweet": "Le vol a Ã©tÃ© annulÃ©, je suis trÃ¨s mÃ©content !"
}
ğŸ” RÃ©ponse attendue :

json
Copier
Modifier
{
  "sentiment": "nÃ©gatif"
}
5ï¸âƒ£ Lancer l'Interface Streamlit
bash
Copier
Modifier
streamlit run streamlit_app.py
ğŸ“Š Suivi des ExpÃ©riences avec MLFlow
ğŸ“Œ MLFlow permet de suivre les modÃ¨les et leur performance.
â¡ï¸ AccÃ©der Ã  lâ€™interface MLFlow en local :

bash
Copier
Modifier
mlflow ui
â¡ï¸ Consulter les logs des expÃ©rimentations :
1ï¸âƒ£ AccÃ©der au dossier mlruns/
2ï¸âƒ£ Voir les courbes d'entraÃ®nement des modÃ¨les

ğŸ›¡ï¸ Tests et DÃ©ploiement
âœ… Tests unitaires avec pytest

bash
Copier
Modifier
pytest tests/test_api.py
â¡ï¸ VÃ©rifie que l'API retourne bien les bons rÃ©sultats.

âœ… CI/CD avec GitHub Actions

Chaque push dÃ©clenche un test automatique.
Si les tests passent, lâ€™API est dÃ©ployÃ©e sur Heroku.
ğŸ“¡ Monitoring avec Azure Application Insights
â¡ï¸ Envoi de logs sur Azure pour suivre l'API en production.
â¡ï¸ DÃ©clenchement d'une alerte email si plus de 3 prÃ©dictions incorrectes en 3 minutes.

ğŸ”— Liens Utiles
ğŸš€ API en production : Lien Heroku
ğŸ“Š MLFlow Tracking : Lien MLFlow
ğŸ“ DÃ©pÃ´t GitHub : Lien vers GitHub
ğŸ“¡ Azure Application Insights : Logs et alertes en temps rÃ©el.

âœ¨ Auteurs
ğŸ‘¨â€ğŸ’» Mourad - DÃ©veloppement et mise en production
ğŸ¢ MIC - Marketing Intelligence Consulting - Commanditaire du projet

yaml
Copier
Modifier

---

## **ğŸ“Œ Pourquoi cette version est amÃ©liorÃ©e ?**
âœ” **Ajout d'explications** sur **les modÃ¨les** et **le choix du LSTM**.  
âœ” **Explication dÃ©taillÃ©e** sur **MLFlow** et **Azure**.  
âœ” **Ajout des tests unitaires** et **CI/CD avec GitHub Actions**.  
âœ” **Meilleure lisibilitÃ© et structuration claire** pour faciliter la comprÃ©hension.  
